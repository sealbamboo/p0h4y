{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:13:53.607340Z",
     "start_time": "2019-05-16T13:13:53.382724Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import contractions\n",
    "import unicodedata\n",
    "\n",
    "# nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "# stopword_list.remove('no')\n",
    "# stopword_list.remove('not')\n",
    "\n",
    "%run -i ./python-code/nlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:13:54.120936Z",
     "start_time": "2019-05-16T13:13:54.110941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\n",
      "\n",
      "\n",
      "us unveils worlds powerful supercomputer beats china us unveiled worlds powerful supercomputer called summit beating previous recordholder chinas sunway taihulight peak performance trillion calculations per second twice fast sunway taihulight capable trillion calculations per second summit servers reportedly take size two tennis courts\n",
      "\n",
      "\n",
      "us unveils world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder china sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court\n"
     ]
    }
   ],
   "source": [
    "full_text = \"US unveils world's most powerful supercomputer, beats China. The US has unveiled the world's most powerful supercomputer called 'Summit', beating the previous record-holder China's Sunway TaihuLight. With a peak performance of 200,000 trillion calculations per second, it is over twice as fast as Sunway TaihuLight, which is capable of 93,000 trillion calculations per second. Summit has 4,608 servers, which reportedly take up the size of two tennis courts.\"\n",
    "print(full_text)\n",
    "print(\"\\n\")\n",
    "\n",
    "test_nlp = nlp(full_text, stopword_list)\n",
    "# print(test_nlp._expand_contractions(full_text))\n",
    "test_norm = test_nlp.normalize()\n",
    "print(test_norm)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"us unveils world powerful supercomputer beat china us unveil world powerful supercomputer call summit beat previous record holder china sunway taihulight peak performance trillion calculation per second twice fast sunway taihulight capable trillion calculation per second summit server reportedly take size two tennis court\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:13:59.010980Z",
     "start_time": "2019-05-16T13:13:58.999987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us unveil world power supercomput beat china us unveil world power supercomput call summit beat previou recordhold china sunway taihulight peak perform trillion calcul per second twice fast sunway taihulight capabl trillion calcul per second summit server reportedli take size two tenni court'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mf_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "mf_stemmer(test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T13:09:35.731816Z",
     "start_time": "2019-05-16T13:09:35.374719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1:  , , stopwords , computer\n",
      "Test2:  Some important text\n",
      "Test3:  Some Accented text\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'stopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mF:\\@PROJECTS\\DSi6+\\p0h4y\\ipynb\\python-code\\nlp.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m \u001b[0mmf_lemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"My system keeps crashing! his crashed yesterday, ours crashes daily\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\@PROJECTS\\DSi6+\\p0h4y\\ipynb\\python-code\\nlp.py\u001b[0m in \u001b[0;36mmf_lemmatize\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;31m# -----------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmf_lemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemma_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-PRON-'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'stopwords'"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# -------------------------------------------------\n",
    "def mf_remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "test = mf_remove_stopwords(\"The, and, if are stopwords, computer is not\")\n",
    "print(\"Test1: \", test)\n",
    "\n",
    "# --------------------------------------\n",
    "# --------------------------------------\n",
    "def mf_strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text\n",
    "\n",
    "# Test function\n",
    "test = mf_strip_html_tags(\"<html><h2>Some important text</h2></html>\")\n",
    "print(\"Test2: \", test)\n",
    "\n",
    "# --------------------------------------\n",
    "# --------------------------------------\n",
    "def mf_remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text\n",
    "\n",
    "# Test funciton\n",
    "test= mf_remove_accented_chars('Sómě Áccěntěd těxt')\n",
    "print(\"Test3: \", test)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# -------------------------------------------------------\n",
    "def mf_remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "mf_remove_special_characters(\"Well this was fun! What do you think? 123#@!\",remove_digits=True)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# -----------------------\n",
    "def mf_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "mf_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# -----------------------\n",
    "def mf_lemmatize(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "mf_lemmatize(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T06:03:06.174537Z",
     "start_time": "2019-05-16T06:03:02.796Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all can't expand contractions I'd think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
